2022-08-05 16:26:32,015 - INFO - balanced sampler is being used
2022-08-05 16:26:42,161 - INFO - ########training dataset: 4802
2022-08-05 16:26:42,162 - INFO - ---------------the train dataloader---------------
2022-08-05 16:26:42,162 - INFO - now using following mask: 8 freq, 16 time
2022-08-05 16:26:42,162 - INFO - now using mix-up with rate 0.000000
2022-08-05 16:26:42,163 - INFO - now process audioset
2022-08-05 16:26:42,163 - INFO - use dataset mean -4.648 and std 4.570 to normalize the input.
2022-08-05 16:26:42,163 - INFO - number of classes is 2
2022-08-05 16:26:42,165 - INFO - ########val dataset: 752
2022-08-05 16:26:42,165 - INFO - ---------------the evaluation dataloader---------------
2022-08-05 16:26:42,166 - INFO - now using following mask: 0 freq, 0 time
2022-08-05 16:26:42,166 - INFO - now using mix-up with rate 0.000000
2022-08-05 16:26:42,167 - INFO - now process audioset
2022-08-05 16:26:42,167 - INFO - use dataset mean -4.648 and std 4.570 to normalize the input.
2022-08-05 16:26:42,168 - INFO - number of classes is 2
2022-08-05 16:26:42,186 - INFO - Total parameter number is : 0.073 million
2022-08-05 16:26:42,186 - INFO - 
Creating experiment directory: ../exp/7.28
2022-08-05 16:26:42,223 - INFO - running on cuda
2022-08-05 16:26:42,361 - INFO - Total parameter number is : 0.073 million
2022-08-05 16:26:42,361 - INFO - Total trainable parameter number is : 0.073 million
2022-08-05 16:26:42,362 - INFO - now training with audioset, main metrics: acc, loss function: BCELoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000002606AF102E0>
2022-08-05 16:26:42,363 - INFO - The learning rate scheduler starts at 10 epoch with decay rate of 0.900 
2022-08-05 16:26:42,363 - INFO - current #steps=0, #epochs=1
2022-08-05 16:26:42,363 - INFO - start training...
2022-08-05 16:26:42,366 - INFO - ---------------
2022-08-05 16:26:42,366 - INFO - 2022-08-05 16:26:42.366167
2022-08-05 16:26:42,366 - INFO - current #epochs=1, #steps=0
2022-08-05 16:26:49,681 - INFO - warm-up learning rate is 0.000000
2022-08-05 16:26:53,051 - INFO - warm-up learning rate is 0.000340
2022-08-05 16:26:54,664 - INFO - warm-up learning rate is 0.000680
2022-08-05 16:26:56,263 - INFO - warm-up learning rate is 0.001020
2022-08-05 16:26:57,885 - INFO - warm-up learning rate is 0.001360
2022-08-05 16:26:59,523 - INFO - warm-up learning rate is 0.001700
2022-08-05 16:27:01,159 - INFO - warm-up learning rate is 0.002040
2022-08-05 16:27:02,779 - INFO - warm-up learning rate is 0.002380
2022-08-05 16:27:04,453 - INFO - warm-up learning rate is 0.002720
2022-08-05 16:27:06,118 - INFO - warm-up learning rate is 0.003060
2022-08-05 16:27:07,743 - INFO - warm-up learning rate is 0.003400
2022-08-05 16:27:09,343 - INFO - warm-up learning rate is 0.003740
2022-08-05 16:27:10,945 - INFO - warm-up learning rate is 0.004080
2022-08-05 16:27:12,555 - INFO - warm-up learning rate is 0.004420
2022-08-05 16:27:14,181 - INFO - warm-up learning rate is 0.004760
2022-08-05 16:27:15,815 - INFO - warm-up learning rate is 0.005100
2022-08-05 16:27:17,429 - INFO - warm-up learning rate is 0.005440
2022-08-05 16:27:19,043 - INFO - warm-up learning rate is 0.005780
2022-08-05 16:27:20,692 - INFO - warm-up learning rate is 0.006120
2022-08-05 16:27:22,340 - INFO - warm-up learning rate is 0.006460
2022-08-05 16:27:23,957 - INFO - warm-up learning rate is 0.006800
2022-08-05 16:27:47,052 - INFO - start validation
2022-08-05 16:27:47,052 - INFO - validate:
2022-08-05 16:55:15,917 - INFO - balanced sampler is being used
2022-08-05 16:55:15,928 - INFO - ########training dataset: 4802
2022-08-05 16:55:15,928 - INFO - ---------------the train dataloader---------------
2022-08-05 16:55:15,928 - INFO - now using following mask: 8 freq, 16 time
2022-08-05 16:55:15,929 - INFO - now using mix-up with rate 0.000000
2022-08-05 16:55:15,929 - INFO - now process audioset
2022-08-05 16:55:15,929 - INFO - use dataset mean -4.648 and std 4.570 to normalize the input.
2022-08-05 16:55:15,929 - INFO - number of classes is 2
2022-08-05 16:55:15,931 - INFO - ########val dataset: 752
2022-08-05 16:55:15,931 - INFO - ---------------the evaluation dataloader---------------
2022-08-05 16:55:15,931 - INFO - now using following mask: 0 freq, 0 time
2022-08-05 16:55:15,931 - INFO - now using mix-up with rate 0.000000
2022-08-05 16:55:15,931 - INFO - now process audioset
2022-08-05 16:55:15,931 - INFO - use dataset mean -4.648 and std 4.570 to normalize the input.
2022-08-05 16:55:15,932 - INFO - number of classes is 2
2022-08-05 16:55:15,940 - INFO - Total parameter number is : 0.073 million
2022-08-05 16:55:15,940 - INFO - 
Creating experiment directory: ../exp/7.28
2022-08-05 16:55:15,974 - INFO - running on cuda
2022-08-05 16:55:16,103 - INFO - Total parameter number is : 0.073 million
2022-08-05 16:55:16,104 - INFO - Total trainable parameter number is : 0.073 million
2022-08-05 16:55:16,104 - INFO - now training with audioset, main metrics: acc, loss function: BCELoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000001DD3DB257F0>
2022-08-05 16:55:16,105 - INFO - The learning rate scheduler starts at 10 epoch with decay rate of 0.900 
2022-08-05 16:55:16,105 - INFO - current #steps=0, #epochs=1
2022-08-05 16:55:16,105 - INFO - start training...
2022-08-05 16:55:16,106 - INFO - ---------------
2022-08-05 16:55:16,106 - INFO - 2022-08-05 16:55:16.106585
2022-08-05 16:55:16,106 - INFO - current #epochs=1, #steps=0
2022-08-05 16:55:21,617 - INFO - warm-up learning rate is 0.000000
2022-08-05 16:55:24,824 - INFO - warm-up learning rate is 0.000340
2022-08-05 16:55:26,242 - INFO - warm-up learning rate is 0.000680
2022-08-05 16:55:27,594 - INFO - warm-up learning rate is 0.001020
2022-08-05 16:55:28,947 - INFO - warm-up learning rate is 0.001360
2022-08-05 16:55:30,289 - INFO - warm-up learning rate is 0.001700
2022-08-05 16:55:31,634 - INFO - warm-up learning rate is 0.002040
2022-08-05 16:55:32,984 - INFO - warm-up learning rate is 0.002380
2022-08-05 16:55:34,330 - INFO - warm-up learning rate is 0.002720
2022-08-05 16:55:35,682 - INFO - warm-up learning rate is 0.003060
2022-08-05 16:55:37,055 - INFO - warm-up learning rate is 0.003400
2022-08-05 16:55:38,431 - INFO - warm-up learning rate is 0.003740
2022-08-05 16:55:39,829 - INFO - warm-up learning rate is 0.004080
2022-08-05 16:55:41,193 - INFO - warm-up learning rate is 0.004420
2022-08-05 16:55:42,551 - INFO - warm-up learning rate is 0.004760
2022-08-05 16:55:43,907 - INFO - warm-up learning rate is 0.005100
2022-08-05 16:55:45,262 - INFO - warm-up learning rate is 0.005440
2022-08-05 16:55:46,622 - INFO - warm-up learning rate is 0.005780
2022-08-05 16:55:47,959 - INFO - warm-up learning rate is 0.006120
2022-08-05 16:55:49,320 - INFO - warm-up learning rate is 0.006460
2022-08-05 16:55:50,667 - INFO - warm-up learning rate is 0.006800
2022-08-05 16:56:11,531 - INFO - start validation
2022-08-05 16:56:11,532 - INFO - validate:
2022-08-05 16:56:23,871 - INFO - validate ensemble:
2022-08-05 16:56:23,887 - INFO - acc: 0.7168 (ng:1.000, ok:0.000)
2022-08-05 16:56:23,888 - INFO - AUC: 0.423130
2022-08-05 16:56:23,888 - INFO - Avg Precision: 0.500000
2022-08-05 16:56:23,888 - INFO - Avg Recall: 1.000000
2022-08-05 16:56:23,889 - INFO - d_prime: -0.274207
2022-08-05 16:56:23,890 - INFO - train_loss: 0.027282
2022-08-05 16:56:23,890 - INFO - valid_loss: 2.931907
2022-08-05 16:56:23,892 - INFO - validation finished
2022-08-05 16:56:23,892 - INFO - @@@@@@@@@@@@@@@@@@@@best epoch:1 acc:0.7167553191489362 loss:2.9319074153900146
2022-08-05 16:56:23,958 - INFO - Epoch-1 lr: 0.0068
2022-08-05 16:56:23,959 - INFO - epoch 1 training time: 67.853
2022-08-05 16:56:23,960 - INFO - ---------------
2022-08-05 16:56:23,960 - INFO - 2022-08-05 16:56:23.960869
2022-08-05 16:56:23,960 - INFO - current #epochs=2, #steps=1684
2022-08-05 16:57:14,771 - INFO - start validation
2022-08-05 16:57:14,772 - INFO - validate:
2022-08-05 16:57:26,886 - INFO - validate ensemble:
2022-08-05 16:57:26,907 - INFO - acc: 0.7168 (ng:1.000, ok:0.000)
2022-08-05 16:57:26,908 - INFO - AUC: 0.402558
2022-08-05 16:57:26,908 - INFO - Avg Precision: 0.500378
2022-08-05 16:57:26,908 - INFO - Avg Recall: 1.000000
2022-08-05 16:57:26,909 - INFO - d_prime: -0.348930
2022-08-05 16:57:26,910 - INFO - train_loss: 0.000011
2022-08-05 16:57:26,910 - INFO - valid_loss: 3.368919
2022-08-05 16:57:26,912 - INFO - validation finished
2022-08-05 16:57:26,912 - INFO - @@@@@@@@@@@@@@@@@@@@best epoch:1 acc:0.7167553191489362 loss:2.9319074153900146
2022-08-05 16:57:26,933 - INFO - Epoch-2 lr: 0.0068
2022-08-05 16:57:26,935 - INFO - epoch 2 training time: 62.974
2022-08-05 16:57:26,935 - INFO - ---------------
2022-08-05 16:57:26,935 - INFO - 2022-08-05 16:57:26.935588
2022-08-05 16:57:26,936 - INFO - current #epochs=3, #steps=3368
2022-08-05 16:58:17,468 - INFO - start validation
2022-08-05 16:58:17,469 - INFO - validate:
2022-08-05 16:58:29,560 - INFO - validate ensemble:
2022-08-05 16:58:29,580 - INFO - acc: 0.7168 (ng:1.000, ok:0.000)
2022-08-05 16:58:29,581 - INFO - AUC: 0.566732
2022-08-05 16:58:29,581 - INFO - Avg Precision: 0.500757
2022-08-05 16:58:29,581 - INFO - Avg Recall: 1.000000
2022-08-05 16:58:29,582 - INFO - d_prime: 0.237671
2022-08-05 16:58:29,582 - INFO - train_loss: 0.000004
2022-08-05 16:58:29,582 - INFO - valid_loss: 3.522470
2022-08-05 16:58:29,585 - INFO - validation finished
2022-08-05 16:58:29,585 - INFO - @@@@@@@@@@@@@@@@@@@@best epoch:1 acc:0.7167553191489362 loss:2.9319074153900146
2022-08-05 16:58:29,607 - INFO - Epoch-3 lr: 0.0068
2022-08-05 16:58:29,608 - INFO - epoch 3 training time: 62.673
2022-08-05 16:58:29,609 - INFO - ---------------
2022-08-05 16:58:29,609 - INFO - 2022-08-05 16:58:29.609148
